{"player1": {"name": "player1", "weight_path": "./resume.pth", "tenpai_pred_weight_path": null, "gpu": 0, "share_model": null}, "player2": {"name": "player2", "weight_path": "./resume.pth", "tenpai_pred_weight_path": null, "gpu": 0, "share_model": null}, "player3": {"name": "palyer3", "weight_path": "./resume.pth", "tenpai_pred_weight_path": null, "gpu": 0, "share_model": null}, "player4": {"name": "player4", "weight_path": "./resume.pth", "tenpai_pred_weight_path": null, "gpu": 0, "share_model": null}, "value_network": {"hidden_size": 512}, "agent": {"actor_network": null, "device": "cuda", "config": null}, "runtime": {"seed": 42, "output_dir": ".", "checkpoint_dir": ".", "tb_log_dir": "tb", "debug": false, "use_cuda": true}, "save_interval": 10000, "stat_interval": 4000, "resume": false, "algorithm": "dsac", "gamma": 0.999, "train_start": 4000, "buffer_size": 10000, "batch_seq_num": 40, "grad_step_num_per_game": 1, "actor_training_offset": 4000, "lr_value": 3e-05, "lr_actor": 1e-05, "random_mps_change": 1, "lr_alpha": 0.0003, "clip_q_epsilon": 1.0, "target_entropy": 0.7, "entropy_penalty_beta": 0.1, "use_avg_q": 0, "alpha_grape": 0.99, "lambd_grape": 0.5, "temp": 1.0, "coef_entropy": 0.01}